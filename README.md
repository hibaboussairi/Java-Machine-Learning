# ğŸ¤– Mini Framework Machine Learning - Java

Un framework de Machine Learning orientÃ© objet dÃ©veloppÃ© en Java, implÃ©mentant des algorithmes classiques de rÃ©gression et classification.

## ğŸ“‹ Description

Ce projet est un mini-framework de Machine Learning conÃ§u dans le cadre d'un projet acadÃ©mique de Programmation OrientÃ©e Objet (POO). Il propose une architecture modulaire et extensible permettant d'entraÃ®ner et d'Ã©valuer diffÃ©rents modÃ¨les de Machine Learning.

## âœ¨ FonctionnalitÃ©s

### Algorithmes ImplÃ©mentÃ©s

- **RÃ©gression LinÃ©aire** : ImplÃ©mentation avec descente de gradient
- **KNN RÃ©gression** : K plus proches voisins pour la rÃ©gression
- **KNN Classification** : K plus proches voisins pour la classification

### Outils de PrÃ©traitement

- **MinMaxScaler** : Normalisation des donnÃ©es entre 0 et 1
- **StandardScaler** : Standardisation des donnÃ©es (moyenne = 0, Ã©cart-type = 1)

### Utilitaires

- **DataUtils** : Division train/test des donnÃ©es
- **Metrics** : Calcul de mÃ©triques (RÂ², Accuracy)

## ğŸ—ï¸ Architecture

```
code/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ Main.java              # Point d'entrÃ©e du programme
â”œâ”€â”€ core/
â”‚   â””â”€â”€ MLModel.java           # Classe abstraite de base pour tous les modÃ¨les
â”œâ”€â”€ linear/
â”‚   â””â”€â”€ LinearRegression.java  # ImplÃ©mentation de la rÃ©gression linÃ©aire
â”œâ”€â”€ knn/
â”‚   â”œâ”€â”€ KNNRegression.java     # KNN pour la rÃ©gression
â”‚   â””â”€â”€ KNNClassification.java # KNN pour la classification
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ Preprocessor.java      # Interface pour le prÃ©traitement
â”‚   â”œâ”€â”€ MinMaxScaler.java      # Normalisation Min-Max
â”‚   â””â”€â”€ StandardScaler.java    # Standardisation
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ Metrics.java           # MÃ©triques d'Ã©valuation
â””â”€â”€ model_selection/
    â””â”€â”€ DataUtils.java         # Utilitaires pour la gestion des donnÃ©es
```

## ğŸš€ Installation et Utilisation

### PrÃ©requis

- Java JDK 8 ou supÃ©rieur
- Un IDE Java (Eclipse, IntelliJ IDEA, VS Code, etc.)

### Compilation

```bash
# Naviguer vers le rÃ©pertoire du projet
cd Java-ML/code

# Compiler tous les fichiers Java
javac -d bin app/*.java core/*.java linear/*.java knn/*.java preprocessing/*.java metrics/*.java model_selection/*.java

# Ou utiliser votre IDE pour compiler le projet
```

### ExÃ©cution

```bash
# ExÃ©cuter le programme principal
java -cp bin ml.app.Main
```

## ğŸ’¡ Exemple d'Utilisation

```java
// CrÃ©er et entraÃ®ner un modÃ¨le de rÃ©gression linÃ©aire
LinearRegression lr = new LinearRegression(0.01, 1000);
lr.train(trainData);

// Faire des prÃ©dictions
double prediction = lr.predict(new double[]{5.0});

// Ã‰valuer le modÃ¨le
double r2Score = lr.score(testData);
System.out.println("RÂ² Score: " + r2Score);
```

## ğŸ“Š RÃ©sultats

Le programme principal (`Main.java`) effectue des tests comparatifs sur :

- DiffÃ©rents ratios de division train/test (20%, 30%)
- DiffÃ©rents taux d'apprentissage pour la rÃ©gression linÃ©aire (0.1, 0.01, 0.001)
- DiffÃ©rentes valeurs de k pour KNN (1, 3, 5, 7)
- Avec et sans prÃ©traitement des donnÃ©es

## ğŸ¯ Concepts POO UtilisÃ©s

- **Abstraction** : Classe abstraite `MLModel`
- **HÃ©ritage** : Tous les modÃ¨les hÃ©ritent de `MLModel`
- **Polymorphisme** : MÃ©thodes `train()`, `predict()`, `score()` redÃ©finies
- **Encapsulation** : Attributs privÃ©s avec getters/setters
- **Interfaces** : `Preprocessor` pour le prÃ©traitement

## ğŸ“ MÃ©triques d'Ã‰valuation

- **RÂ² Score** : Pour les modÃ¨les de rÃ©gression (mesure la qualitÃ© de l'ajustement)
- **Accuracy** : Pour les modÃ¨les de classification (taux de bonnes prÃ©dictions)


## ğŸ‘¥ Auteur
**Hiba Boussairi**

